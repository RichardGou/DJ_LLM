{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:08:14.792630Z",
     "iopub.status.busy": "2025-03-17T13:08:14.792285Z",
     "iopub.status.idle": "2025-03-17T13:08:18.221212Z",
     "shell.execute_reply": "2025-03-17T13:08:18.220310Z",
     "shell.execute_reply.started": "2025-03-17T13:08:14.792601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install required package (if not already installed)\n",
    "\n",
    "# !pip install miditok kagglehub mido pydub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Download dataset\n",
    "for improvement see : GiantMIDI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:08:25.384155Z",
     "iopub.status.busy": "2025-03-17T13:08:25.383826Z",
     "iopub.status.idle": "2025-03-17T13:08:25.523051Z",
     "shell.execute_reply": "2025-03-17T13:08:25.522289Z",
     "shell.execute_reply.started": "2025-03-17T13:08:25.384127Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /teamspace/studios/this_studio/.cache/kagglehub/datasets/pictureinthenoise/music-generation-with-giantmidi-piano/versions/2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Download the dataset from Kaggle using kagglehub\n",
    "import kagglehub\n",
    "dataset_path = kagglehub.dataset_download(\"pictureinthenoise/music-generation-with-giantmidi-piano\")\n",
    "print(\"Path to dataset files:\", dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:08:35.219458Z",
     "iopub.status.busy": "2025-03-17T13:08:35.219085Z",
     "iopub.status.idle": "2025-03-17T13:08:35.224476Z",
     "shell.execute_reply": "2025-03-17T13:08:35.223497Z",
     "shell.execute_reply.started": "2025-03-17T13:08:35.219428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from miditok import REMI\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from scipy.io.wavfile import write as wavwrite\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import mido\n",
    "import matplotlib.pyplot as plt\n",
    "# import subprocess\n",
    "# from pydub import AudioSegment\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) dataset:\n",
    "sources: bigger with more musics types: https://github.com/asigalov61/Tegridy-MIDI-Dataset\n",
    "\n",
    "\n",
    "super famous, piano : https://github.com/bytedance/GiantMIDI-Piano. **The one used**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:08:39.822737Z",
     "iopub.status.busy": "2025-03-17T13:08:39.822409Z",
     "iopub.status.idle": "2025-03-17T13:08:48.183402Z",
     "shell.execute_reply": "2025-03-17T13:08:48.182441Z",
     "shell.execute_reply.started": "2025-03-17T13:08:39.822713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10845 MIDI files.\n"
     ]
    }
   ],
   "source": [
    "midi_files = []\n",
    "# Recursively search for files ending with .mid or .midi\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.mid', '.midi')):\n",
    "            midi_files.append(os.path.join(root, file))\n",
    "\n",
    "if not midi_files:\n",
    "    raise ValueError(\"No MIDI files found in the downloaded dataset.\")\n",
    "\n",
    "print(f\"Found {len(midi_files)} MIDI files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:08:48.184784Z",
     "iopub.status.busy": "2025-03-17T13:08:48.184535Z",
     "iopub.status.idle": "2025-03-17T13:08:58.763176Z",
     "shell.execute_reply": "2025-03-17T13:08:58.762281Z",
     "shell.execute_reply.started": "2025-03-17T13:08:48.184763Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been split into train, validation, and test sets.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Split files into train (80%), validation (10%), and test (10%) sets\n",
    "random.seed(42)\n",
    "random.shuffle(midi_files)\n",
    "n_total = len(midi_files)\n",
    "n_train = int(n_total * 0.8)\n",
    "n_val = int(n_total * 0.1)\n",
    "# The rest for testing:\n",
    "n_test = n_total - n_train - n_val\n",
    "\n",
    "train_files = midi_files[:n_train]\n",
    "val_files = midi_files[n_train:n_train+n_val]\n",
    "test_files = midi_files[n_train+n_val:]\n",
    "\n",
    "# Create directories for the splits\n",
    "os.makedirs(\"data/train\", exist_ok=True)\n",
    "os.makedirs(\"data/val\", exist_ok=True)\n",
    "os.makedirs(\"data/test\", exist_ok=True)\n",
    "\n",
    "# Copy files into their corresponding directories\n",
    "for file in train_files:\n",
    "    shutil.copy(file, \"data/train/\")\n",
    "for file in val_files:\n",
    "    shutil.copy(file, \"data/val/\")\n",
    "for file in test_files:\n",
    "    shutil.copy(file, \"data/test/\")\n",
    "\n",
    "print(\"Dataset has been split into train, validation, and test sets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) playing with dataset + examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:09:14.628370Z",
     "iopub.status.busy": "2025-03-17T13:09:14.628029Z",
     "iopub.status.idle": "2025-03-17T13:09:14.940727Z",
     "shell.execute_reply": "2025-03-17T13:09:14.939763Z",
     "shell.execute_reply.started": "2025-03-17T13:09:14.628339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_midi(file_path, start_sec=0, end_sec=None):\n",
    "\n",
    "    mid = mido.MidiFile(file_path)\n",
    "    \n",
    "    notes = []\n",
    "    times = []\n",
    "    current_time = 0\n",
    "    \n",
    "    # Iterate over all MIDI messages and track cumulative time\n",
    "    for msg in mid:\n",
    "        current_time += msg.time\n",
    "        if msg.type in ['note_on', 'note_off']:\n",
    "            # Only add notes within the selected time window\n",
    "            if current_time >= start_sec and (end_sec is None or current_time <= end_sec):\n",
    "                notes.append(msg.note)\n",
    "                times.append(current_time)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(times, notes, color='blue', marker='o')\n",
    "    title_end = f\"{end_sec}s\" if end_sec is not None else \"end\"\n",
    "    plt.title(f'Visualisation du fichier MIDI (from {start_sec}s to {title_end})')\n",
    "    plt.xlabel('Temps (s)')\n",
    "    plt.ylabel('Note')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "#midi_file = 'data/train/a-jag-je-t-aime-juliette-oxc7fd0zn8o.mid'\n",
    "# Plot from 10 seconds to 30 seconds of the MIDI file\n",
    "#plot_midi(midi_file, start_sec=10, end_sec=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer:\n",
    "Pierre bonne intuition REMI bonne idée askip CP mieux pour la classification il met pas mal de point à REMI dans ce papier: https://arxiv.org/pdf/2107.05223\n",
    "\n",
    "et en même temps dans le cours https://leria.univ-angers.fr/wp-content/uploads/2023/09/Prez-Seminaire-LERIA-2023.pdf ça dit que BPE + Rémi c'eest mieux\n",
    "comme si CP ça avait pas de BPE possible (à chercher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T12:09:05.400796Z",
     "iopub.status.busy": "2025-03-17T12:09:05.400577Z",
     "iopub.status.idle": "2025-03-17T12:09:05.480583Z",
     "shell.execute_reply": "2025-03-17T12:09:05.479659Z",
     "shell.execute_reply.started": "2025-03-17T12:09:05.400778Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files :  14512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/miditok/tokenizations/remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    }
   ],
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a tokenizer configuration\n",
    "config = TokenizerConfig(num_velocities=16, use_chords=True, use_programs=True)\n",
    "tokenizer_remi = REMI(config)\n",
    "\n",
    "# Path to your MIDI files used to train the tokenizer\n",
    "files_paths = list(Path(\"data\").rglob(\"*.mid\"))\n",
    "print(\"number of files : \",len(files_paths))\n",
    "\n",
    "# Train the tokenizer using Byte Pair Encoding (BPE) with a vocab size of 20000 \n",
    "#tokenizer.train(vocab_size=20000, files_paths=files_paths)# UNCOMMENT IF NEED TO TRAIN AGAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train BPE tokenizer to have 20000 tokens, aprox 2h de training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-15T22:13:37.574631Z",
     "iopub.status.busy": "2025-03-15T22:13:37.573882Z",
     "iopub.status.idle": "2025-03-15T22:13:38.832879Z",
     "shell.execute_reply": "2025-03-15T22:13:38.831826Z",
     "shell.execute_reply.started": "2025-03-15T22:13:37.574592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optionally, push the tokenizer to the Hugging Face Hub (requires valid credentials)\n",
    "#tokenizer.push_to_hub(\"Richatte2000/tokenizer_midi_piano\", private=True, token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T12:09:06.136736Z",
     "iopub.status.busy": "2025-03-17T12:09:06.136435Z",
     "iopub.status.idle": "2025-03-17T12:09:06.337159Z",
     "shell.execute_reply": "2025-03-17T12:09:06.336487Z",
     "shell.execute_reply.started": "2025-03-17T12:09:06.136706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = REMI.from_pretrained(\"Richatte2000/tokenizer_midi_piano\", use_auth_token=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combien de tokens par seconde\n",
    "Vitesse moyenne de tokenisation : 13.10 tokens par seconde.\n",
    "\n",
    "import time\n",
    "\n",
    "train_files = list(Path(\"data/train\").glob(\"*.mid\"))[:100]\n",
    "\n",
    "total_tokens = 0\n",
    "total_time = 0.0\n",
    "\n",
    "for file in train_files:\n",
    "    # Tokenisation du fichier MIDI\n",
    "    tokens = tokenizer.midi_to_tokens(file)\n",
    "    duration = mido.MidiFile(file).length\n",
    "    \n",
    "    num_tokens = len(tokens)\n",
    "    total_tokens += num_tokens\n",
    "    total_time += duration\n",
    "    print(f\"{file.name}: {num_tokens} tokens en {duration:.4f} secondes.\")\n",
    "\n",
    "if total_time > 0:\n",
    "    avg_tokens_per_sec = total_tokens / total_time\n",
    "    print(f\"\\nVitesse moyenne de tokenisation : {avg_tokens_per_sec:.2f} tokens par seconde.\")\n",
    "else:\n",
    "    print(\"Temps total nul, impossible de calculer la vitesse.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T12:10:16.636214Z",
     "iopub.status.busy": "2025-03-17T12:10:16.635894Z",
     "iopub.status.idle": "2025-03-17T12:10:16.650517Z",
     "shell.execute_reply": "2025-03-17T12:10:16.649499Z",
     "shell.execute_reply.started": "2025-03-17T12:10:16.636190Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T12:15:09.217853Z",
     "iopub.status.busy": "2025-03-17T12:15:09.217380Z",
     "iopub.status.idle": "2025-03-17T12:15:09.587917Z",
     "shell.execute_reply": "2025-03-17T12:15:09.586653Z",
     "shell.execute_reply.started": "2025-03-17T12:15:09.217815Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_files = list(Path(\"data/train\").glob(\"*.mid\"))[:100]\n",
    "file = train_files[0]\n",
    "\n",
    "config = TokenizerConfig(num_velocities=16, use_chords=True, use_programs=True)\n",
    "tokenizer_remi = REMI(config)\n",
    "\n",
    "tokens_raw_remi = tokenizer_remi.encode(file)\n",
    "print(tokens_raw_remi[2222])\n",
    "# Si vous avez les IDs des tokens, vous pouvez les convertir en tokens lisibles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO : création des datasets avec le nouveau tokenizer entrainé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T10:46:01.492020Z",
     "iopub.status.busy": "2025-03-16T10:46:01.491677Z",
     "iopub.status.idle": "2025-03-16T10:48:14.544611Z",
     "shell.execute_reply": "2025-03-16T10:48:14.543909Z",
     "shell.execute_reply.started": "2025-03-16T10:46:01.491993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from miditok.utils import split_files_for_training\n",
    "from random import shuffle\n",
    "# Assurer la présence des tokens spéciaux\n",
    "if not hasattr(tokenizer, \"pad_token_id\") or tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = \"<PAD>\"\n",
    "    tokenizer.pad_token_id = 0\n",
    "if not hasattr(tokenizer, \"eos_token_id\") or tokenizer.eos_token_id is None:\n",
    "    tokenizer.eos_token = \"<EOS>\"\n",
    "    tokenizer.eos_token_id = 2\n",
    "\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Dataset segmenté : découpe des fichiers MIDI en chunks de 512 tokens\n",
    "# =============================================================================\n",
    "os.makedirs(r\"data_chunks/train\", exist_ok=True)\n",
    "os.makedirs(r\"data_chunks/test\", exist_ok=True)\n",
    "os.makedirs(r\"data_chunks/val\", exist_ok=True)\n",
    "\n",
    "# UNCOMMENT TO CHUNK DATASET\n",
    "# subsets = [\"train\", \"test\", \"val\"]\n",
    "# for sub in subsets:\n",
    "#     midi_paths = list(Path(f\"data/{sub}\").resolve().glob(\"**/*.mid\"))\n",
    "#     total_num_files = len(midi_paths)\n",
    "#     shuffle(midi_paths)\n",
    "#     dataset_chunks_dir = Path(f\"data_chunks/{sub}\")\n",
    "#     split_files_for_training(\n",
    "#         files_paths=midi_paths,\n",
    "#         tokenizer=tokenizer,\n",
    "#         save_dir=dataset_chunks_dir,\n",
    "#         max_seq_len=512,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also potentially augment the segments of the Dataset ? Not sure what it does, but it is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform data augmentation\n",
    "# augment_dataset(\n",
    "#     subset_chunks_dir,\n",
    "#     pitch_offsets=[-12, 12],\n",
    "#     velocity_offsets=[-4, 4],\n",
    "#     duration_offsets=[-0.5, 0.5],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader and Collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class DatasetMidi apparently tokenizes an entire Dataset in the format of a torch/transformers item, so simple e,ougn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T10:49:39.397267Z",
     "iopub.status.busy": "2025-03-16T10:49:39.396983Z",
     "iopub.status.idle": "2025-03-16T10:49:39.401229Z",
     "shell.execute_reply": "2025-03-16T10:49:39.400493Z",
     "shell.execute_reply.started": "2025-03-16T10:49:39.397246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = DatasetMIDI(files_paths=list(Path(\"data_chunks/train\").resolve().glob(\"**/*.mid\")),\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_seq_len=512,\n",
    "                            bos_token_id=tokenizer.pad_token_id,\n",
    "                            eos_token_id=tokenizer[\"BOS_None\"],\n",
    ")\n",
    "val_dataset = DatasetMIDI(files_paths=list(Path(\"data_chunks/val\").resolve().glob(\"**/*.mid\")),\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_seq_len=512,\n",
    "                            bos_token_id=tokenizer.pad_token_id,\n",
    "                            eos_token_id=tokenizer[\"BOS_None\"],\n",
    ")\n",
    "test_dataset = DatasetMIDI(files_paths=list(Path(\"data_chunks/test\").resolve().glob(\"**/*.mid\")),\n",
    "                            tokenizer=tokenizer,\n",
    "                            max_seq_len=512,\n",
    "                            bos_token_id=tokenizer.pad_token_id,\n",
    "                            eos_token_id=tokenizer[\"BOS_None\"]\n",
    ")\n",
    "collator=DataCollator(tokenizer.pad_token_id, copy_inputs_as_labels=True, shift_labels=True)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16, collate_fn=collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 9295,  4285,   437,  ...,     0,     0,     0],\n",
      "        [ 1296,  2289,   434,  ...,   947,  1110,   764],\n",
      "        [ 1834,  2915, 19058,  ...,  6137,  2474,   453],\n",
      "        ...,\n",
      "        [ 1176,  2163,   432,  ...,   548,  2144,  3654],\n",
      "        [ 2184,  5812,  3153,  ...,     0,     0,     0],\n",
      "        [11580,   461,   991,  ...,     0,     0,     0]]), 'labels': tensor([[ 4285,   437,  7603,  ...,  -100,  -100,  -100],\n",
      "        [ 2289,   434,  1310,  ...,  1110,   764,  1280],\n",
      "        [ 2915, 19058,  3841,  ...,  2474,   453,  2420],\n",
      "        ...,\n",
      "        [ 2163,   432, 10977,  ...,  2144,  3654,   481],\n",
      "        [ 5812,  3153,  4588,  ...,  -100,  -100,  -100],\n",
      "        [  461,   991,   879,  ...,  -100,  -100,  -100]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "print((next(iter(train_loader))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bart compatible tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from miditok import TokSequence\n",
    "# from sympy import are_similar\n",
    "\n",
    "\n",
    "# print(tokenizer.special_tokens, tokenizer.special_tokens_ids)\n",
    "# class BartCompatibleMIDITokenizer:\n",
    "#     def __init__(self, tokenizer):\n",
    "#         self.tokenizer = tokenizer\n",
    "#         special_tokens = tokenizer.special_tokens\n",
    "#         special_tokens_ids = tokenizer.special_tokens_ids\n",
    "#         self.pad_token, self.bos_token, self.eos_token, self.mask_token = special_tokens\n",
    "#         self.pad_token_id, self.bos_token_id, self.eos_token_id, self.mask_token_id = special_tokens_ids\n",
    "#         self.vocab_size = tokenizer.vocab_size\n",
    "\n",
    "#     def encode(self, midi_data, add_special_tokens=True):\n",
    "#         \"\"\" Input: Path(\"path/to/a/midi/file)\n",
    "#             returns: TokSequence\"\"\"\n",
    "#         tokens = self.tokenizer.encode(midi_data)\n",
    "\n",
    "#         if add_special_tokens:\n",
    "#             tokenss = TokSequence([self.bos_token], are_ids_encoded=True)+tokens+TokSequence([self.eos_token], are_ids_encoded=True)\n",
    "#             tokenss._ticks_bars = tokens._ticks_bars # copy properties from OG TokSequence item\n",
    "#             tokenss._ticks_beats = tokens._ticks_beats\n",
    "#         return tokenss\n",
    "    \n",
    "#     def decode(self, tokens_to_decode):\n",
    "#         # Filter out special tokens before decoding\n",
    "#         filtered_toks = [t for t in tokens_to_decode if t not in [\n",
    "#             self.pad_token, self.mask_token, \n",
    "#             self.bos_token, self.eos_token\n",
    "#         ]]\n",
    "        \n",
    "#         # Use your existing tokenizer to decode filtered tokens\n",
    "#         return self.tokenizer.decode(filtered_toks)\n",
    "    \n",
    "#     def create_masked_inputs(self, sequence, mask_prob=0.10, max_span_length=2):\n",
    "#         \"\"\"Input : sequence: List of token ids\"\"\"\n",
    "#         input_ids = sequence.copy()\n",
    "#         labels = [-100] * len(sequence)  # -100 is the ignore index in PyTorch\n",
    "        \n",
    "#         # For infilling, randomly mask spans\n",
    "#         seq_length = len(sequence)\n",
    "#         if seq_length > 10:  # Only mask if sequence is long enough\n",
    "#             # Determine number of spans to mask\n",
    "#             num_tokens_to_mask = int(seq_length * mask_prob)\n",
    "#             num_spans = max(1, num_tokens_to_mask // max_span_length)\n",
    "            \n",
    "#             # Keep track of masked positions\n",
    "#             masked_indices = set()\n",
    "            \n",
    "#             for _ in range(num_spans):\n",
    "#                 span_length = random.randint(1, max_span_length)\n",
    "                \n",
    "#                 # Find a valid starting position\n",
    "#                 attempts = 0\n",
    "#                 while attempts < 10:  # Limit attempts to prevent infinite loops\n",
    "#                     start_idx = random.randint(1, seq_length - span_length - 1)  # Avoid BOS/EOS\n",
    "#                     # Check if this span overlaps with existing masks\n",
    "#                     if not any(i in masked_indices for i in range(start_idx, start_idx + span_length)):\n",
    "#                         break\n",
    "#                     attempts += 1\n",
    "                \n",
    "#                 if attempts >= 10:\n",
    "#                     continue  # Skip this span if can't find a valid position\n",
    "                \n",
    "#                 # Replace first token with mask token\n",
    "#                 input_ids[start_idx] = self.mask_token_id\n",
    "#                 masked_indices.add(start_idx)\n",
    "                \n",
    "#                 # Set labels for the entire masked span\n",
    "#                 for i in range(start_idx, min(start_idx + span_length, seq_length)):\n",
    "#                     # For the label, we keep the original token\n",
    "#                     labels[i] = sequence[i]\n",
    "#                     # For spans longer than 1, remove subsequent tokens from input\n",
    "#                     if i > start_idx:\n",
    "#                         input_ids[i] = -100\n",
    "#                         masked_indices.add(i)\n",
    "        \n",
    "#         # Remove the -100 values from input_ids\n",
    "#         input_ids = [x for x in input_ids if x != -100]\n",
    "        \n",
    "#         return input_ids, labels\n",
    "    \n",
    "# midi_tidbit = Path(r\"C:\\Users\\pipau\\Documents\\Python\\VSCode\\LLM\\data_chunks\\train\\a-jag-je-t-aime-juliette-oxc7fd0zn8o_0.mid\").resolve()\n",
    "# bartTokenizer = BartCompatibleMIDITokenizer(tokenizer)\n",
    "# og = tokenizer.encode(midi_tidbit)\n",
    "# print(og.ids)\n",
    "# tokenizer.encode_token_ids(og)\n",
    "# print(og.ids)\n",
    "# # print(bartTokenizer.encode(midi_tidbit))\n",
    "# print(tokenizer.decode(og.ids) == bartTokenizer.decode(og.ids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bart training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartConfig, BartForConditionalGeneration\n",
    "special_tokens = tokenizer.special_tokens\n",
    "special_tokens_ids = tokenizer.special_tokens_ids\n",
    "pad_token, bos_token, eos_token, mask_token = special_tokens\n",
    "pad_token_id, bos_token_id, eos_token_id, mask_token_id = special_tokens_ids\n",
    "\n",
    "config = BartConfig(vocab_size=tokenizer.vocab_size,\n",
    "                max_position_embeddings=1024,\n",
    "                encoder_layers=6,\n",
    "                decoder_layers=6,\n",
    "                encoder_attention_heads=8,\n",
    "                decoder_attention_heads=8,\n",
    "                d_model=512,\n",
    "                bos_token_id=bos_token_id,\n",
    "                eos_token_id=eos_token_id,\n",
    "                pad_token_id=pad_token_id,\n",
    "                mask_token_id=mask_token_id)\n",
    "model = BartForConditionalGeneration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 7445/7445 [1:41:14<00:00,  1.23it/s, loss=1.7001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Complete!\n",
      "Average Loss: 6.0870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   2%|▏         | 184/7445 [02:28<1:48:19,  1.12it/s, loss=1.3985]"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                lr=5e-5, # 3e-4\n",
    "                weight_decay=0.01)\n",
    "\n",
    "epochs = 10 \n",
    "grad_clip = 1.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # print(input_ids, attention_mask, labels)\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), \n",
    "            grad_clip\n",
    "        )\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        \n",
    "        # Update tracking\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            # 'lr': f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
    "        })\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch+1} Complete!\")\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "    # print(f\"Learning Rate: {scheduler.get_last_lr()[0]:.2e}\\n\")\n",
    "    torch.save(model, f'model_epoch{epoch}.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspiration but for a GPT model\n",
    "https://www.kaggle.com/code/jeongyoonlee/tf-keras-bart-baseline-training-inference\n",
    "\n",
    "\n",
    "https://medium.com/@noufalsamsudin/generating-music-with-gpt-b0f4ab738b58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BART MODEL TRAINED WITH HUGGIN FACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-15T23:46:17.541546Z",
     "iopub.status.idle": "2025-03-15T23:46:17.541874Z",
     "shell.execute_reply": "2025-03-15T23:46:17.541742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(\"Richatte2000/bart-midi-finetuned\", use_auth_token=\"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\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5464432,
     "sourceId": 9061487,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
