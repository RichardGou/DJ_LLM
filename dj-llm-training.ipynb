{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11149598,"sourceType":"datasetVersion","datasetId":6956012}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0) requirements","metadata":{}},{"cell_type":"code","source":"# Install required package (if not already installed)\n\n!pip install miditok kagglehub mido pydub\n","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:10:24.184919Z","iopub.execute_input":"2025-03-24T17:10:24.185102Z","iopub.status.idle":"2025-03-24T17:10:30.865221Z","shell.execute_reply.started":"2025-03-24T17:10:24.185085Z","shell.execute_reply":"2025-03-24T17:10:30.864268Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting miditok\n  Downloading miditok-3.0.5.post1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.9)\nCollecting mido\n  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\nRequirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from miditok) (0.29.0)\nRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from miditok) (1.26.4)\nCollecting symusic>=0.5.0 (from miditok)\n  Downloading symusic-0.5.7-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from miditok) (0.21.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from miditok) (4.67.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from kagglehub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->miditok) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19->miditok) (2.4.1)\nCollecting pySmartDL (from symusic>=0.5.0->miditok)\n  Downloading pySmartDL-1.3.4-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from symusic>=0.5.0->miditok) (4.3.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19->miditok) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19->miditok) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19->miditok) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19->miditok) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19->miditok) (2024.2.0)\nDownloading miditok-3.0.5.post1-py3-none-any.whl (158 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading mido-1.3.3-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading symusic-0.5.7-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\nInstalling collected packages: pySmartDL, mido, symusic, miditok\nSuccessfully installed miditok-3.0.5.post1 mido-1.3.3 pySmartDL-1.3.4 symusic-0.5.7\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"https://www.kaggle.com/code/yashsrivastava51213/bart-pretraining-from-scratch\n\nTRAINING FROM SCRATCH BART","metadata":{}},{"cell_type":"markdown","source":"## b) import dependencies","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport mido\nimport matplotlib.pyplot as plt\n\nfrom miditok import REMI, TokenizerConfig\nfrom miditok.pytorch_data import DatasetMIDI\nfrom pathlib import Path\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:33:56.604192Z","iopub.execute_input":"2025-03-24T17:33:56.604556Z","iopub.status.idle":"2025-03-24T17:33:56.609139Z","shell.execute_reply.started":"2025-03-24T17:33:56.604530Z","shell.execute_reply":"2025-03-24T17:33:56.608282Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from miditok import REMI, TokenizerConfig\ntokenizer = REMI.from_pretrained(\"Richatte2000/tokenizer_midi_piano\", use_auth_token=\"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\")","metadata":{"execution":{"iopub.status.busy":"2025-03-24T17:10:42.815856Z","iopub.execute_input":"2025-03-24T17:10:42.816130Z","iopub.status.idle":"2025-03-24T17:10:43.321012Z","shell.execute_reply.started":"2025-03-24T17:10:42.816111Z","shell.execute_reply":"2025-03-24T17:10:43.320055Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.28M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f45b13f40a5d4842a1ba0ca4d3435e0e"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/miditok/tokenizations/remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n  super().__init__(tokenizer_config, params)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# The following code will only execute\n# successfully when compression is complete\n\"\"\"\nimport kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"pierrepauchet/midi-piano-chunks\")\n\nprint(\"Path to dataset files:\", path)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T14:38:44.566917Z","iopub.execute_input":"2025-03-24T14:38:44.567208Z","iopub.status.idle":"2025-03-24T14:38:44.572074Z","shell.execute_reply.started":"2025-03-24T14:38:44.567183Z","shell.execute_reply":"2025-03-24T14:38:44.571366Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\nimport kagglehub\\n\\n# Download latest version\\npath = kagglehub.dataset_download(\"pierrepauchet/midi-piano-chunks\")\\n\\nprint(\"Path to dataset files:\", path)\\n'"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from miditok.pytorch_data import DatasetMIDI, DataCollator\nfrom torch.utils.data import DataLoader\nfrom pathlib import Path \n\ntrain_dataset = DatasetMIDI(files_paths=list(Path(\"/kaggle/input/midi-piano-chunks/train\").resolve().glob(\"**/*.mid\")),\n                            tokenizer=tokenizer,\n                            max_seq_len=512,\n                            bos_token_id=tokenizer.pad_token_id,\n                            eos_token_id=tokenizer[\"BOS_None\"],\n)\n\nprint(\"Train dataset loaded\")\nval_dataset = DatasetMIDI(files_paths=list(Path(\"/kaggle/input/midi-piano-chunks/val\").resolve().glob(\"**/*.mid\")),\n                            tokenizer=tokenizer,\n                            max_seq_len=512,\n                            bos_token_id=tokenizer.pad_token_id,\n                            eos_token_id=tokenizer[\"BOS_None\"],\n)\nprint(\"Val dataset loaded\")\ntest_dataset = DatasetMIDI(files_paths=list(Path(\"/kaggle/input/midi-piano-chunks/test\").resolve().glob(\"**/*.mid\")),\n                            tokenizer=tokenizer,\n                            max_seq_len=512,\n                            bos_token_id=tokenizer.pad_token_id,\n                            eos_token_id=tokenizer[\"BOS_None\"]\n)\nprint(\"Test dataset loaded\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T17:10:49.730012Z","iopub.execute_input":"2025-03-24T17:10:49.730321Z","iopub.status.idle":"2025-03-24T17:17:46.730088Z","shell.execute_reply.started":"2025-03-24T17:10:49.730297Z","shell.execute_reply":"2025-03-24T17:17:46.729314Z"}},"outputs":[{"name":"stdout","text":"done\ndone\ndone\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Récupération des tokens spéciaux\nspecial_tokens = tokenizer.special_tokens\nspecial_tokens_ids = tokenizer.special_tokens_ids\npad_token, bos_token, eos_token, mask_token = special_tokens\npad_token_id, bos_token_id, eos_token_id, mask_token_id = special_tokens_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T17:34:37.528356Z","iopub.execute_input":"2025-03-24T17:34:37.528693Z","iopub.status.idle":"2025-03-24T17:34:37.532657Z","shell.execute_reply.started":"2025-03-24T17:34:37.528665Z","shell.execute_reply":"2025-03-24T17:34:37.531761Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom miditok.pytorch_data import DataCollator\n\nclass DataCollatorForInfilling(DataCollator):\n    \"\"\"\n    Data collator qui hérite du DataCollator de miditok et qui ajoute une corruption :\n    pour chaque exemple, on masque UNE séquence contiguë de n tokens (n ~ Poisson(15)).\n    La séquence est choisie aléatoirement parmi tous les tokens valides (excluant BOS et EOS).\n    Les tokens masqués dans l'input sont remplacés par mask_token_id et dans les labels,\n    ces positions conservent la valeur originale (les autres positions sont mises à -100).\n    \"\"\"\n    def __init__(self, pad_token_id, mask_token_id, poisson_lambda=15, copy_inputs_as_labels=True, shift_labels=True):\n        super().__init__(pad_token_id, copy_inputs_as_labels=copy_inputs_as_labels, shift_labels=shift_labels)\n        # On stocke explicitement ces attributs dans l'objet\n        self.pad_token_id = pad_token_id\n        self.mask_token_id = mask_token_id\n        self.poisson_lambda = poisson_lambda\n\n    def __call__(self, batch):\n        # On commence par appliquer le collator de base pour le padding et le shift des labels si demandé\n        batch = super().__call__(batch)\n        # Récupération des input_ids et création d'une copie pour les labels\n        inputs = batch[\"input_ids\"].clone()\n        labels = inputs.clone()\n        # On initialise toutes les positions à -100 (pour ignorer celles qui ne seront pas masquées)\n        labels[:] = -100\n\n        # Pour chaque exemple de la batch\n        for i in range(inputs.size(0)):\n            seq = inputs[i]\n            # On récupère les positions valides (non-padding)\n            valid_positions = (seq != self.pad_token_id).nonzero(as_tuple=False).view(-1)\n            # Exclure le premier et le dernier token (souvent BOS/EOS)\n            valid_positions = valid_positions[(valid_positions != 0) & (valid_positions != (seq.size(0) - 1))]\n            if len(valid_positions) == 0:\n                continue\n\n            # Nombre de tokens à masquer selon une loi de Poisson\n            n_mask = np.random.poisson(self.poisson_lambda)\n\n            # Déterminer la longueur disponible dans la séquence continue de tokens valides\n            # On suppose ici que les tokens valides sont contigus (ce qui est généralement le cas avant padding)\n            available_length = valid_positions[-1].item() - valid_positions[0].item() + 1\n            # On ne masque pas plus que ce qui est disponible\n            span_length = min(n_mask, available_length)\n            if span_length <= 0:\n                continue\n\n            # Choix aléatoire d'un indice de départ tel que le bloc contigu reste dans les positions valides\n            start_idx = np.random.randint(valid_positions[0].item(), valid_positions[-1].item() - span_length + 2)\n            # Masquage de la séquence contiguë\n            for j in range(start_idx, start_idx + span_length):\n                labels[i, j] = inputs[i, j]      # On garde la valeur originale dans les labels\n                inputs[i, j] = self.mask_token_id # On remplace dans l'input par le token mask\n\n        batch[\"input_ids\"] = inputs\n        batch[\"labels\"] = labels\n        return batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T17:50:54.895400Z","iopub.execute_input":"2025-03-24T17:50:54.895681Z","iopub.status.idle":"2025-03-24T17:50:54.903171Z","shell.execute_reply.started":"2025-03-24T17:50:54.895659Z","shell.execute_reply":"2025-03-24T17:50:54.902333Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"collator = DataCollatorForInfilling(\n    pad_token_id=tokenizer.pad_token_id,\n    mask_token_id=mask_token_id,\n    poisson_lambda=15,\n    copy_inputs_as_labels=True,\n    shift_labels=True\n)\ntrain_loader = DataLoader(train_dataset, shuffle=True, batch_size=16, collate_fn=collator)\nval_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collator)\ntest_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T17:50:56.871332Z","iopub.execute_input":"2025-03-24T17:50:56.871607Z","iopub.status.idle":"2025-03-24T17:50:56.875835Z","shell.execute_reply.started":"2025-03-24T17:50:56.871586Z","shell.execute_reply":"2025-03-24T17:50:56.875044Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"sample = next(iter(train_loader))\n\nprint(\"Inpus ID : \",sample['input_ids'][0])\nprint(\"-------------------\")\n\nprint(\"LABELS : \",sample['labels'][0])\nprint(\"-------------------\")\n\nprint(\"Attention MASK : \", sample['attention_mask'][0])\nprint(\"-------------------\")\n\nL_input,L_label,L_attention = sample['input_ids'][0], sample['labels'][0], sample['attention_mask'][0]\n\n#Boucle pour check\nfor i in range(0,len(L_input)):\n    if L_input[i] == mask_token_id:\n        print(\"input : \",L_input[i] ,\"labels : \",L_label[i] ,\"attention mask : \",L_attention[i] )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:00:40.910633Z","iopub.execute_input":"2025-03-24T18:00:40.910908Z","iopub.status.idle":"2025-03-24T18:00:41.254577Z","shell.execute_reply.started":"2025-03-24T18:00:40.910887Z","shell.execute_reply":"2025-03-24T18:00:41.253799Z"}},"outputs":[{"name":"stdout","text":"Inpus ID :  tensor([  897, 10269,  4146,  2613,  4468,   493,  2920, 16996,  3525,  3388,\n         3299,   488,  1548, 15449, 19248, 13684,  2354,  6723,  2156,   615,\n         1261, 14843, 18117, 15540,  2765,  2155,  2891,   487,  1169, 15655,\n        13179,  1196, 15156,  2820,  3897,   548,  1242, 14015, 17381, 16161,\n         5409,  3790,   526,  1067,  2289,   421,   463,  2020, 17565,  3516,\n         3711,  2599,  4830,   506,  1396, 16762,   493,  1294,   463,  3057,\n         4606,  4906,   586,  1080,  5078,  4468,  3033,   526,  2981,  3692,\n         5769,   647,  7452,  7566,   582,  2070,   474,  1987,   474,  2077,\n         2410,   560,  1949,   507,  2032,   507,  1891,   507,  2005,  2470,\n        11909,  1986,   474,  1111,  4197,  2709,   599,  1998,   507,  1979,\n          507,  1989,   507,  1161,   777,   455,   474,  1955,   474,  1836,\n          507,  4952,   522,  1720,  6041,  7794,   474,  2210,   507,  2142,\n          507,  2099,   507,  2052,   584,  2013,   507,  1011,  2675,   506,\n         1966,   465,  1984,   474,  2027,  2558,  3676,   506,  1954,   507,\n         2048,   507,  2004,   507,   915,  3415,  4713, 19683,   507,  1993,\n          499,  2003,   507,  2010,  2860, 15235,  2007,   474,  2239,   507,\n         2702,   474,  2561,  3215,  4384,   523,  2106,   474,  2136,   474,\n         2038,   489,  1587,  3162,  4203,   477,  1949,   477,  2032,   463,\n         1891,   477,  1944,  3254,  9985,  1471,  2004,   481,  2006,   466,\n         1992,   477,  1090,  3892,   911,   455,   481,  2003,   481,  2010,\n          481,  1827,   481,  3717,   623,  3909,   463,  2481,   477,  2266,\n          477,  2095,   481,  2070,   477,  1995,   477,  2022,   463,  1984,\n        17589,   489,   953,   504,  1954,   489,  2048,   770,  1961,   602,\n         1133,  4819,  2439,   684,  1237, 14015, 17381, 15567,   463,  1067,\n         2289,   421,  1796,  2444,  4620,   782,   550,  1826,  2334,   465,\n         1596,  3172,  3050,  2155,   548,  1396, 14876, 16518,   463,  1639,\n         3606,  3388,  3495,   646,  1211, 15361,   474,  1172, 15686,  1796,\n         4902,  6957,   622,  1273,  2334, 12236, 18366, 14822, 17521,   463,\n         1154,  2243,  2570,  2518, 10920,  1232,   463,   880,  2734,  3388,\n         3299,   488,  2920, 18649, 19249, 15448,  2492,  2053,  6957,   624,\n         1359, 16162,   463,  1261, 15719,   491,  1192,  3387,  3204,   505,\n         1258, 15540,   489,  1169, 17918,  6853,  4361,  7717,   842,  9090,\n         1052,   535,  1237, 16615,  3171,  3790,   488,  1220, 17612,  4596,\n          463,  1661, 18913,  3703,  2086,  3986,  4713,   506,  1548, 14386,\n          493,  1359,   463,  3045,  5209,  4906,   504,  1080,  6706,  6087,\n         6825,   506,  3083,  5446, 11213,   615,   411,  2981,   910,   436,\n          777,   483,  3200,   529,  2594,   491,  2192,   491,  4074,   515,\n         2500,   491,  1842,   491,  1510,   598,  1428,   598,  1758,   491,\n         2993,  6830,  9646,  3200,   473,  2398,   586,  2579,   628,  4498,\n          996,   455,   756,   470,   598,  2754,   569,  3130,   473,  1982,\n          598,  1814, 18490,   515,  1832,   598,  1828,   586,  1463,   598,\n         1776,  4588, 10560,   551,  1781,   491,  2340,   504,   894,  4723,\n         7289,  7370,   515,  2883,   504,  1860,   491,  1612,  2885,  4575,\n         4948,   529,  1209,  4087,   537,  1855,   491,  1085,  4978,  3897,\n          551,  1212,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n            3,     3,     3,     3,   561,  1828,   598,  1030, 16449,   717,\n         2219,   488,  2835,   615,  3071,   529,  2769,   598,  3268, 19223,\n         9650,   515,  2581,   491,  2404,   491,  2338,   515,  2333,   491,\n         1782,   473,  1437,   598,  1401,   598,  1778,   473,     4,   173,\n          485,  8069,  7370,  2424,   473,     0,     0,     0,     0,     0,\n            0,     0])\n-------------------\nLABELS :  tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,  515, 1628,\n         515, 1662, 5621, 5034,  605, 1232,  537, 1668,  504, 3440, 2385,  717,\n        1975,  561, 1542,  491, 1318, 2522,  923, 1249, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n        -100, -100, -100, -100, -100, -100, -100, -100])\n-------------------\nAttention MASK :  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n-------------------\ninput :  tensor(3) labels :  tensor(515) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(1628) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(515) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(1662) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(5621) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(5034) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(605) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(1232) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(537) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(1668) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(504) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(3440) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(2385) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(717) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(1975) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(561) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(1542) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(491) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(1318) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(2522) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(923) attention mask :  tensor(1, dtype=torch.int32)\ninput :  tensor(3) labels :  tensor(1249) attention mask :  tensor(1, dtype=torch.int32)\n","output_type":"stream"}],"execution_count":58},{"cell_type":"markdown","source":"## bart training","metadata":{}},{"cell_type":"code","source":"#############################\n# Définition du modèle BART de base (non pré-entraîné)\n#############################\nfrom transformers import BartConfig, BartForConditionalGeneration\n\nconfig = BartConfig(\n    vocab_size=tokenizer.vocab_size,\n    max_position_embeddings=1024,\n    encoder_layers=6,\n    decoder_layers=6,\n    encoder_attention_heads=8,\n    decoder_attention_heads=8,\n    d_model=512,\n    bos_token_id=bos_token_id,\n    eos_token_id=eos_token_id,\n    pad_token_id=pad_token_id,\n    mask_token_id=mask_token_id\n)\nmodel = BartForConditionalGeneration(config)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:00:47.413277Z","iopub.execute_input":"2025-03-24T18:00:47.413576Z","iopub.status.idle":"2025-03-24T18:01:16.961114Z","shell.execute_reply.started":"2025-03-24T18:00:47.413555Z","shell.execute_reply":"2025-03-24T18:01:16.960342Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2014c411d6140ce8381dceb41f549bc"}},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\n\noptimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)\nnum_epochs = 10\ntotal_steps = len(train_loader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps=int(0.1 * total_steps),\n                                            num_training_steps=total_steps)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:05:53.250102Z","iopub.execute_input":"2025-03-24T18:05:53.250891Z","iopub.status.idle":"2025-03-24T18:05:53.284485Z","shell.execute_reply.started":"2025-03-24T18:05:53.250858Z","shell.execute_reply":"2025-03-24T18:05:53.283703Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"#############################\n# Boucle d'entraînement avec évaluation sur la validation et push sur Hugging Face\n#############################\nfor epoch in range(num_epochs):\n    model.train()\n    total_train_loss = 0\n    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n    \n    for batch in progress_bar:\n        # Déplacement des données vers le device\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        \n        # Clipping des gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        \n        total_train_loss += loss.item()\n        progress_bar.set_postfix({\"loss\": loss.item()})\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n    \n    # Évaluation sur le jeu de validation\n    model.eval()\n    total_val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            total_val_loss += outputs.loss.item()\n    avg_val_loss = total_val_loss / len(val_loader)\n    \n    print(f\"\\nEpoch {epoch+1} terminé : Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f}\\n\")\n    \n    # Push du modèle sur Hugging Face Hub\n    # Remplacez \"USERNAME/REPO_NAME\" et \"YOUR_TOKEN\" par vos identifiants et token.\n    model.push_to_hub(\"Richatte2000/\", use_auth_token=\"aaaaaaa\", commit_message=f\"Epoch {epoch+1}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-24T18:05:55.168749Z","iopub.execute_input":"2025-03-24T18:05:55.169036Z","iopub.status.idle":"2025-03-24T18:11:09.777397Z","shell.execute_reply.started":"2025-03-24T18:05:55.169015Z","shell.execute_reply":"2025-03-24T18:11:09.776092Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/10:   4%|▍         | 183/4615 [05:14<2:06:53,  1.72s/it, loss=9.07]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-344f540ec8ac>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1640\u001b[0m                 )\n\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1643\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1311\u001b[0m                 \u001b[0;31m# the manual implementation that requires a 4D causal mask in all cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                 \u001b[0;31m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 encoder_attention_mask = _prepare_4d_attention_mask_for_sdpa(\n\u001b[0m\u001b[1;32m   1314\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                     \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py\u001b[0m in \u001b[0;36m_prepare_4d_attention_mask_for_sdpa\u001b[0;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;31m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture data-dependent controlflows.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tracing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":61}]}